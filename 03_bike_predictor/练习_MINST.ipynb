{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# “火炬上的深度学习\"第一次大作业\n",
    "\n",
    "在这个作业中，你需要半独立地利用人工神经网络搭建一个手写数字识别器\n",
    "\n",
    "本文件是集智学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"简单的 LeNet-5类型的卷积神经网络模型，MNIST例子.\n",
    "\"\"\"\n",
    "\n",
    "#所有依赖包\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#定义一系列常数\n",
    "SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/' #图像数据如果没下载，可以从这个地址下载\n",
    "WORK_DIRECTORY = 'data' #存储的路径名\n",
    "IMAGE_SIZE = 28 #每张图片的大小尺寸\n",
    "NUM_CHANNELS = 1  #每张图片的通道数\n",
    "PIXEL_DEPTH = 255 #像素的深度0-255\n",
    "NUM_LABELS = 10 #手写数字，一共十种\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取MINST图形文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载图像文件，如果文件已经存在，那么就不下载。\n",
    "def maybe_download(filename):\n",
    "    \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n",
    "    if not os.path.isdir(WORK_DIRECTORY):\n",
    "        os.mkdir(WORK_DIRECTORY)\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        size = os.path.getsize(filepath)\n",
    "        print('Successfully downloaded', filename, size, 'bytes.')\n",
    "    return filepath\n",
    "# Get the data.\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    # filename: 文件存放的路径，num_images: 读入的图片个数\n",
    "    \"\"\"将图像解压缩展开，读入成一个4维的张量： [image index（图像的编码）, y（纵坐标）, x（横坐标）, channels（通道）].\n",
    "    我们将数组中的数值范围从原来的[0, 255]降低到了[-0.5, 0.5]范围内\n",
    "    \"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"将label的数据文件解压缩，并将label读成64位的整数\"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels\n",
    "\n",
    "# 将数据解压缩并存储到数组中，60000张图片，60000个label，测试集中有10000张图片\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "train_X = train_data.reshape(len(train_data), -1)\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "train_Y = train_labels\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "test_X = test_data.reshape(len(test_data), -1)\n",
    "\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "test_Y = test_labels\n",
    "train_X.shape, train_Y.shape\n",
    "\n",
    "# train_X, train_Y 中分别存储的是向量化的训练数据与标签\n",
    "# test_X, test_Y 中分别存储的是向量化的测试数据与标签\n",
    "# train_X的维度是60000个样本，784个分量的图像向量\n",
    "# test_X的维度是10000个样本，784个分量的图像向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.size\n",
    "\n",
    "train_Y.size\n",
    "\n",
    "train_X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在这里写下你自己的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一步：定义神经网络，提示，可以使用简单的torch.nn.SequentialModel\n",
    "\n",
    "本文件是集智学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 提示：需要考虑好网络有几层，每一层有多少个节点\n",
    "# net = torch.nn.Sequential(\n",
    "#    torch.nn.Linear(784, 10),\n",
    "#    torch.nn.Sigmoid(),\n",
    "# )\n",
    "\n",
    "# # 问题：如果要增加新的神经网络层怎么办？\n",
    "\n",
    "input_size = train_X.shape[1]\n",
    "output_size = 1\n",
    "hidden_size = 10\n",
    "batch_size = 128\n",
    "\n",
    "neuc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_size, hidden_size),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(hidden_size, output_size)\n",
    ")\n",
    "\n",
    "\n",
    "cost = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(neuc.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二步：构造损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三步：开始训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提示：有两重循环，最外面层是多少次的训练，里层为对数据批次（batch）的循环\n",
    "\n",
    "\n",
    "#神经网络训练循环\n",
    "batch_size = 128\n",
    "losses = []\n",
    "for i in range(1000):\n",
    "    #每128个样本点被划分为一个撮，在循环的时候一撮一撮地读取\n",
    "    batch_loss = []\n",
    "    #start和end分别是提取一个batch数据的起始和终止下标\n",
    "    for start in range(0, len(train_X), batch_size):\n",
    "        end = start + batch_size if start + batch_size < len(train_X) else len(train_X)\n",
    "        \n",
    "        xx = torch.tensor(train_X[start:end],dtype = torch.float, requires_grad = True)  #从训练数据train_X中提取数据\n",
    "        yy = torch.tensor(train_Y[start:end],dtype = torch.float, requires_grad = True) #从训练数据train_Y中提取标签，注意标签数据为整数，因此相应的tensor也要为long\n",
    "\n",
    "        predict = neuc(xx) #用神经网络进行预测\n",
    "        loss = cost(predict, yy) \n",
    "        optimizer.zero_grad() #清空梯度\n",
    "        loss.backward() #开始反向传播\n",
    "        optimizer.step() #开始更新梯度\n",
    "        batch_loss.append(loss.data.numpy())\n",
    "    \n",
    "    #每隔100步输出一下损失值（loss）\n",
    "    if i % 100==0:\n",
    "        losses.append(np.mean(batch_loss))\n",
    "        print(i, np.mean(batch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 请在这里写下你自己的回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 请绘制上面训练过程的损失函数曲线，以及'''错误率曲线'''！！！\n",
    "batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印输出损失值\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "plt.plot(np.arange(len(losses))*100,losses, 'o-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,7))\n",
    "plt.plot(np.arange(len(batch_loss)), batch_loss, 'o-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四步：在测试集上测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，labels是数据之中的正确答案\"\"\"\n",
    "    predictions = np.argmax(predictions, 1)\n",
    "    return 100.0 - (100.0 *np.sum( predictions == labels) /predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分多个batch计算测试结果\n",
    "errors = []\n",
    "losses = []\n",
    "i = 0\n",
    "for start in range(0, len(test_X), batch_size):\n",
    "    end = start + batch_size if start + batch_size < len(test_X) else len(test_X)\n",
    "    i += 1\n",
    "    x = torch.tensor(test_X[start:end], dtype = torch.float, requires_grad = True)\n",
    "    y = torch.tensor(test_Y[start:end], dtype = torch.float, requires_grad = True)\n",
    "    predictions = neuc(x)\n",
    "    loss = cost(predictions, y)\n",
    "    err_rate = error_rate(predictions.data.numpy(), y.data.numpy())\n",
    "    errors.append(err_rate)\n",
    "    losses.append(loss.data.numpy())\n",
    "    print(i, err_rate)\n",
    "\n",
    "print('平均错误率：%.4f'%(np.mean(errors)/100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用单个图像进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随便从数据集中读入一张图片，并绘制出来\n",
    "idx = 100\n",
    "muteimg = test_data[idx, 0, :, :]\n",
    "plt.imshow(muteimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算识别结果\n",
    "x = torch.tensor(test_X[idx, :].reshape(1,-1), dtype = torch.float, requires_grad = True)\n",
    "predict = neuc(x)\n",
    "np.argmax(predict.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 升级版"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你已经运行跑通上面的所有代码，那么请你尝试对其进行更改，让测试集上面的识别错误率进一步下降，看看能不能到1%以下\n",
    "\n",
    "提示：可以考虑增加层的深度\n",
    "\n",
    "本文件是集智学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
