{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度强化学习－用卷积神经网络实现AI玩Flappy Bird游戏\n",
    "\n",
    "本节课我们结合Flappy bird游戏，详细讲述了深度强化学习原理，以及如何训练一个神经网络来玩儿游戏\n",
    "\n",
    "整个代码包括了利用PyGame包实现一个Flappy Bird游戏，卷积神经网络的定义与实现，以及深度强化学习算法。\n",
    "\n",
    "本程序参考了AI玩Flappy Bird的TensorFlow版本：https://github.com/yenchenlin/DeepLearningFlappyBird\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第X课的配套源代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、PyGAME实现Flappy Bird游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这部分中，我们调用PyGame包实现了一个Flappy Bird游戏。通过PyGame，我们可以非常方便的加载图片、音频，来快速实现小游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 加载游戏所需的必要资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.5\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# 加载游戏中的所有资源，包括图片以及音频\n",
    "# 调用PyGame包，关于该包的安装，请参看：http://www.pygame.org/wiki/GettingStarted\n",
    "import pygame\n",
    "\n",
    "# 需要获取操作系统类型，故而调用sys包\n",
    "import sys\n",
    "def load():\n",
    "    # 加载各类资源的函数\n",
    "    # 精灵在不同状态下的图片\n",
    "    PLAYER_PATH = (\n",
    "            'assets/sprites/redbird-upflap.png',\n",
    "            'assets/sprites/redbird-midflap.png',\n",
    "            'assets/sprites/redbird-downflap.png'\n",
    "    )\n",
    "\n",
    "    # 背景图地址\n",
    "    BACKGROUND_PATH = 'assets/sprites/background-black.png'\n",
    "\n",
    "    # 管道图片所在的地址\n",
    "    PIPE_PATH = 'assets/sprites/pipe-green.png'\n",
    "\n",
    "    IMAGES, SOUNDS, HITMASKS = {}, {}, {}\n",
    "\n",
    "    # 加载成绩数字所需的图片\n",
    "    IMAGES['numbers'] = (\n",
    "        pygame.image.load('assets/sprites/0.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/1.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/2.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/3.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/4.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/5.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/6.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/7.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/8.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/9.png').convert_alpha()\n",
    "    )\n",
    "\n",
    "    # 加载地面的图片\n",
    "    IMAGES['base'] = pygame.image.load('assets/sprites/base.png').convert_alpha()\n",
    "\n",
    "    # 加载声音文件（在不同的系统中，声音文件扩展名不同）\n",
    "    if 'win' in sys.platform:\n",
    "        soundExt = '.wav'\n",
    "    else:\n",
    "        soundExt = '.ogg'\n",
    "\n",
    "    SOUNDS['die']    = pygame.mixer.Sound('assets/audio/die' + soundExt)\n",
    "    SOUNDS['hit']    = pygame.mixer.Sound('assets/audio/hit' + soundExt)\n",
    "    SOUNDS['point']  = pygame.mixer.Sound('assets/audio/point' + soundExt)\n",
    "    SOUNDS['swoosh'] = pygame.mixer.Sound('assets/audio/swoosh' + soundExt)\n",
    "    SOUNDS['wing']   = pygame.mixer.Sound('assets/audio/wing' + soundExt)\n",
    "\n",
    "    # 加载背景图\n",
    "    IMAGES['background'] = pygame.image.load(BACKGROUND_PATH).convert()\n",
    "\n",
    "    # s加载精灵图\n",
    "    IMAGES['player'] = (\n",
    "        pygame.image.load(PLAYER_PATH[0]).convert_alpha(),\n",
    "        pygame.image.load(PLAYER_PATH[1]).convert_alpha(),\n",
    "        pygame.image.load(PLAYER_PATH[2]).convert_alpha(),\n",
    "    )\n",
    "\n",
    "    # 加载水管\n",
    "    IMAGES['pipe'] = (\n",
    "        pygame.transform.rotate(\n",
    "            pygame.image.load(PIPE_PATH).convert_alpha(), 180),\n",
    "        pygame.image.load(PIPE_PATH).convert_alpha(),\n",
    "    )\n",
    "\n",
    "    # 获得水管的蒙板\n",
    "    HITMASKS['pipe'] = (\n",
    "        getHitmask(IMAGES['pipe'][0]),\n",
    "        getHitmask(IMAGES['pipe'][1]),\n",
    "    )\n",
    "\n",
    "    # 玩家的蒙板\n",
    "    HITMASKS['player'] = (\n",
    "        getHitmask(IMAGES['player'][0]),\n",
    "        getHitmask(IMAGES['player'][1]),\n",
    "        getHitmask(IMAGES['player'][2]),\n",
    "    )\n",
    "\n",
    "    #返回了三个字典，每个字典的值分别存储图像、声音和蒙板\n",
    "    return IMAGES, SOUNDS, HITMASKS\n",
    "\n",
    "def getHitmask(image):\n",
    "    \"\"\"根据图像的alpha，获得蒙板\"\"\"\n",
    "    #所谓蒙板就是指将图像中的主体从整个图像中抠出来的技术，从而方便与其它的对象合成到一起\n",
    "    #蒙板用一个boolean类型的列表来存储\n",
    "    mask = []\n",
    "    for x in range(image.get_width()):\n",
    "        mask.append([])\n",
    "        for y in range(image.get_height()):\n",
    "            mask[x].append(bool(image.get_at((x,y))[3]))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 实现Flappy Bird的游戏逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载程序所需的包\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import pygame\n",
    "import pygame.surfarray as surfarray\n",
    "from pygame.locals import *\n",
    "from itertools import cycle\n",
    "%matplotlib inline\n",
    "\n",
    "FPS = 30 #帧率\n",
    "SCREENWIDTH  = 288 #屏幕的宽度\n",
    "SCREENHEIGHT = 512 #屏幕的高度\n",
    "\n",
    "pygame.init() #游戏初始化\n",
    "FPSCLOCK = pygame.time.Clock() #定义程序时钟\n",
    "SCREEN = pygame.display.set_mode((SCREENWIDTH, SCREENHEIGHT)) #定义屏幕对象\n",
    "pygame.display.set_caption('Flappy Bird') #设定窗口名称\n",
    "\n",
    "IMAGES, SOUNDS, HITMASKS = load() #加载游戏资源\n",
    "PIPEGAPSIZE = 100 # 定义两个水管之间的宽度\n",
    "BASEY = SCREENHEIGHT * 0.79 #设定基地的高度\n",
    "\n",
    "# 设定小鸟属性：宽度、高度等\n",
    "PLAYER_WIDTH = IMAGES['player'][0].get_width()\n",
    "PLAYER_HEIGHT = IMAGES['player'][0].get_height()\n",
    "\n",
    "# 设定水管属性：高度、宽度\n",
    "PIPE_WIDTH = IMAGES['pipe'][0].get_width()\n",
    "PIPE_HEIGHT = IMAGES['pipe'][0].get_height()\n",
    "\n",
    "#背景宽度\n",
    "BACKGROUND_WIDTH = IMAGES['background'].get_width()\n",
    "\n",
    "PLAYER_INDEX_GEN = cycle([0, 1, 2, 1])\n",
    "\n",
    "# 游戏模型类\n",
    "class GameState:\n",
    "    def __init__(self):\n",
    "        # 初始化\n",
    "        # 初始成绩、玩家索引、循环迭代都为0\n",
    "        self.score = self.playerIndex = self.loopIter = 0\n",
    "        \n",
    "        #设定玩家的初始位置\n",
    "        self.playerx = int(SCREENWIDTH * 0.2)\n",
    "        self.playery = int((SCREENHEIGHT - PLAYER_HEIGHT) / 2)\n",
    "        self.basex = 0\n",
    "        # 地面的初始移位\n",
    "        self.baseShift = IMAGES['base'].get_width() - BACKGROUND_WIDTH\n",
    "\n",
    "        # 生成两个随机的水管\n",
    "        newPipe1 = getRandomPipe()\n",
    "        newPipe2 = getRandomPipe()\n",
    "        \n",
    "        # 设定初始水管的位置x，y坐标\n",
    "        self.upperPipes = [\n",
    "            {'x': SCREENWIDTH, 'y': newPipe1[0]['y']},\n",
    "            {'x': SCREENWIDTH + (SCREENWIDTH / 2), 'y': newPipe2[0]['y']},\n",
    "        ]\n",
    "        self.lowerPipes = [\n",
    "            {'x': SCREENWIDTH, 'y': newPipe1[1]['y']},\n",
    "            {'x': SCREENWIDTH + (SCREENWIDTH / 2), 'y': newPipe2[1]['y']},\n",
    "        ]\n",
    "\n",
    "        # 定义玩家的属性\n",
    "        self.pipeVelX = -4\n",
    "        self.playerVelY    =  0    # 小鸟在y轴上的速度，初始设置维playerFlapped\n",
    "        self.playerMaxVelY =  10   # Y轴上的最大速度, 也就是最大的下降速度\n",
    "        self.playerMinVelY =  -8   # Y轴向上的最大速度\n",
    "        self.playerAccY    =   1   # 小鸟往下落的加速度\n",
    "        self.playerFlapAcc =  -9   # 扇动翅膀的加速度\n",
    "        self.playerFlapped = False # 玩家是否煽动了翅膀\n",
    "\n",
    "    def frame_step(self, input_actions):\n",
    "        # input_actions是一个行动数组，分别存储了0或者1两个动作的激活情况\n",
    "        # 游戏每一帧的循环\n",
    "        pygame.event.pump()\n",
    "\n",
    "        # 每一步的默认回报\n",
    "        reward = 0.1\n",
    "        terminal = False\n",
    "\n",
    "        # 限定每一帧只能做一个动作\n",
    "        if sum(input_actions) != 1:\n",
    "            raise ValueError('Multiple input actions!')\n",
    "\n",
    "        # input_actions[0] == 1: 对应什么都不做\n",
    "        # input_actions[1] == 1: 对应小鸟煽动了翅膀\n",
    "        if input_actions[1] == 1:\n",
    "            # 小鸟煽动翅膀向上\n",
    "            if self.playery > -2 * PLAYER_HEIGHT:\n",
    "                self.playerVelY = self.playerFlapAcc\n",
    "                self.playerFlapped = True\n",
    "                #SOUNDS['wing'].play()\n",
    "\n",
    "        # 检查是否通过了管道，如果通过，则增加成绩\n",
    "        playerMidPos = self.playerx + PLAYER_WIDTH / 2\n",
    "        for pipe in self.upperPipes:\n",
    "            pipeMidPos = pipe['x'] + PIPE_WIDTH / 2\n",
    "            if pipeMidPos <= playerMidPos < pipeMidPos + 4:\n",
    "                self.score += 1\n",
    "                #SOUNDS['point'].play()\n",
    "                reward = 1\n",
    "\n",
    "        # playerIndex轮换\n",
    "        if (self.loopIter + 1) % 3 == 0:\n",
    "            self.playerIndex = next(PLAYER_INDEX_GEN)\n",
    "        self.loopIter = (self.loopIter + 1) % 30\n",
    "        self.basex = -((-self.basex + 100) % self.baseShift)\n",
    "\n",
    "        # 小鸟运动\n",
    "        if self.playerVelY < self.playerMaxVelY and not self.playerFlapped:\n",
    "            self.playerVelY += self.playerAccY\n",
    "        if self.playerFlapped:\n",
    "            self.playerFlapped = False\n",
    "        self.playery += min(self.playerVelY, BASEY - self.playery - PLAYER_HEIGHT)\n",
    "        if self.playery < 0:\n",
    "            self.playery = 0\n",
    "\n",
    "        # 管道的移动\n",
    "        for uPipe, lPipe in zip(self.upperPipes, self.lowerPipes):\n",
    "            uPipe['x'] += self.pipeVelX\n",
    "            lPipe['x'] += self.pipeVelX\n",
    "\n",
    "        # 当管道快到左侧边缘的时候，产生新的管道\n",
    "        if 0 < self.upperPipes[0]['x'] < 5:\n",
    "            newPipe = getRandomPipe()\n",
    "            self.upperPipes.append(newPipe[0])\n",
    "            self.lowerPipes.append(newPipe[1])\n",
    "\n",
    "        # 当第一个管道移出屏幕的时候，就把它删除\n",
    "        if self.upperPipes[0]['x'] < -PIPE_WIDTH:\n",
    "            self.upperPipes.pop(0)\n",
    "            self.lowerPipes.pop(0)\n",
    "\n",
    "        # 检查碰撞\n",
    "        isCrash= checkCrash({'x': self.playerx, 'y': self.playery,\n",
    "                             'index': self.playerIndex},\n",
    "                            self.upperPipes, self.lowerPipes)\n",
    "        # 如果有碰撞发生，则游戏结束，terminal＝True\n",
    "        if isCrash:\n",
    "            #SOUNDS['hit'].play()\n",
    "            #SOUNDS['die'].play()\n",
    "            terminal = True\n",
    "            self.__init__()\n",
    "            reward = -1\n",
    "\n",
    "        # 将所有角色都根据每个角色的坐标画到屏幕上\n",
    "        SCREEN.blit(IMAGES['background'], (0,0))\n",
    "\n",
    "        for uPipe, lPipe in zip(self.upperPipes, self.lowerPipes):\n",
    "            SCREEN.blit(IMAGES['pipe'][0], (uPipe['x'], uPipe['y']))\n",
    "            SCREEN.blit(IMAGES['pipe'][1], (lPipe['x'], lPipe['y']))\n",
    "\n",
    "        SCREEN.blit(IMAGES['base'], (self.basex, BASEY))\n",
    "        \n",
    "        # print score so player overlaps the score\n",
    "        # showScore(self.score)\n",
    "        SCREEN.blit(IMAGES['player'][self.playerIndex],\n",
    "                    (self.playerx, self.playery))\n",
    "\n",
    "        # 将当前的游戏屏幕生成一个二维画面返回\n",
    "        image_data = pygame.surfarray.array3d(pygame.display.get_surface())\n",
    "        pygame.display.update()\n",
    "        FPSCLOCK.tick(FPS)\n",
    "        #print self.upperPipes[0]['y'] + PIPE_HEIGHT - int(BASEY * 0.2)\n",
    "        # 该函数的输出有三个变量：游戏当前帧的游戏画面，当前获得的游戏得分，游戏是否已经结束\n",
    "        return image_data, reward, terminal\n",
    "    \n",
    "\n",
    "def getRandomPipe():\n",
    "    #随机生成管道的函数\n",
    "    \"\"\"returns a randomly generated pipe\"\"\"\n",
    "    # 两个管道之间的竖直间隔从下列数中直接取\n",
    "    gapYs = [20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    index = random.randint(0, len(gapYs)-1)\n",
    "    gapY = gapYs[index]\n",
    "\n",
    "    #设定新生成管道的位置\n",
    "    gapY += int(BASEY * 0.2)\n",
    "    pipeX = SCREENWIDTH + 10\n",
    "\n",
    "    # 返回管道的坐标\n",
    "    return [\n",
    "        {'x': pipeX, 'y': gapY - PIPE_HEIGHT},  # upper pipe\n",
    "        {'x': pipeX, 'y': gapY + PIPEGAPSIZE},  # lower pipe\n",
    "    ]\n",
    "\n",
    "\n",
    "def showScore(score):\n",
    "    # 在屏幕上直接展示成绩的函数\n",
    "    \"\"\"displays score in center of screen\"\"\"\n",
    "    scoreDigits = [int(x) for x in list(str(score))]\n",
    "    totalWidth = 0 # total width of all numbers to be printed\n",
    "\n",
    "    for digit in scoreDigits:\n",
    "        totalWidth += IMAGES['numbers'][digit].get_width()\n",
    "\n",
    "    Xoffset = (SCREENWIDTH - totalWidth) / 2\n",
    "\n",
    "    for digit in scoreDigits:\n",
    "        SCREEN.blit(IMAGES['numbers'][digit], (Xoffset, SCREENHEIGHT * 0.1))\n",
    "        Xoffset += IMAGES['numbers'][digit].get_width()\n",
    "\n",
    "\n",
    "def checkCrash(player, upperPipes, lowerPipes):\n",
    "    # 检测碰撞的函数，基本思路为：将每一个物体都看作是一个矩形区域，然后检查两个矩形区域是否有碰撞\n",
    "    # 检查碰撞是细到每个对象的图像蒙板级别，而不单纯是看矩形之间的碰撞\n",
    "    \"\"\"returns True if player collders with base or pipes.\"\"\"\n",
    "    pi = player['index']\n",
    "    player['w'] = IMAGES['player'][0].get_width()\n",
    "    player['h'] = IMAGES['player'][0].get_height()\n",
    "\n",
    "    # 检查小鸟是否碰撞到了地面\n",
    "    if player['y'] + player['h'] >= BASEY - 1:\n",
    "        return True\n",
    "    else:\n",
    "        # 检查小鸟是否与管道碰撞\n",
    "        playerRect = pygame.Rect(player['x'], player['y'],\n",
    "                      player['w'], player['h'])\n",
    "\n",
    "        for uPipe, lPipe in zip(upperPipes, lowerPipes):\n",
    "            # 上下管道矩形\n",
    "            uPipeRect = pygame.Rect(uPipe['x'], uPipe['y'], PIPE_WIDTH, PIPE_HEIGHT)\n",
    "            lPipeRect = pygame.Rect(lPipe['x'], lPipe['y'], PIPE_WIDTH, PIPE_HEIGHT)\n",
    "\n",
    "            # 获得每个元素的蒙板\n",
    "            pHitMask = HITMASKS['player'][pi]\n",
    "            uHitmask = HITMASKS['pipe'][0]\n",
    "            lHitmask = HITMASKS['pipe'][1]\n",
    "\n",
    "            # 检查是否与上下管道相撞\n",
    "            uCollide = pixelCollision(playerRect, uPipeRect, pHitMask, uHitmask)\n",
    "            lCollide = pixelCollision(playerRect, lPipeRect, pHitMask, lHitmask)\n",
    "\n",
    "            if uCollide or lCollide:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def pixelCollision(rect1, rect2, hitmask1, hitmask2):\n",
    "    \"\"\"在像素级别检查两个物体是否发生碰撞\"\"\"\n",
    "    rect = rect1.clip(rect2)\n",
    "\n",
    "    if rect.width == 0 or rect.height == 0:\n",
    "        return False\n",
    "\n",
    "    # 确定矩形框，并针对矩形框中的每个像素进行循环，查看两个对象是否碰撞\n",
    "    x1, y1 = rect.x - rect1.x, rect.y - rect1.y\n",
    "    x2, y2 = rect.x - rect2.x, rect.y - rect2.y\n",
    "\n",
    "    for x in range(rect.width):\n",
    "        for y in range(rect.height):\n",
    "            if hitmask1[x1+x][y1+y] and hitmask2[x2+x][y2+y]:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 对游戏做小测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAACwZJREFUeJzt3X+s1XUdx/HXq3slfhgTs00FFuicPzILxwylXBNilkybtoHL/vAf+iMTnc2Ra8O21ubmTP9oLka6lgxZyB+OOWWVm80l8woVwtVGaHAFE3+kZho63/1xjnrFe8/3eznfL99z3jwff3EOn/vhzdl98v1+zzmX44gQgJw+1fQAAOpD4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kNljHprZ5exxQs4hw0RqO4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBipQK3fantZ23vtr2q7qEAVMNF/2WT7QFJf5f0DUkjkp6UdHVE7OrwNbzRBahZVW90uUDS7ojYExGHJN0v6YpuhwNQvzKBz5S0b9TtkfZ9H2N7he0h20NVDQegO2Xeiz7WacAnTsEjYo2kNRKn6ECvKHMEH5E0e9TtWZL21zMOgCqVCfxJSWfYnmt7kqTlkh6sdywAVSg8RY+I92xfJ+kRSQOS7omInbVPBqBrhS+THdGmXIMDtePnwYFjHIEDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kVBm57tu1HbQ/b3ml75dEYDED3HBGdF9inSDolIrbZ/oykpyR9OyJ2dfiazpsC6FpEuGhN4RE8Ig5ExLb2r9+UNCxpZvfjAajbhK7Bbc+RNE/S1jqGAVCtwbILbR8v6QFJN0TEG2P8/gpJKyqcDUCXCq/BJcn2cZI2S3okIu4osZ5rcKBmZa7ByzzJZkm/kfRqRNxQ5g8mcKB+VQX+VUl/krRD0vvtu2+JiIc6fA2BAzWrJPAjQeBA/Sp5mQxA/yJwIDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCAxAgcSKx247QHb221vrnMgANWZyBF8paThugYBUL1SgdueJekySWvrHQdAlcoewe+UdLOk98dbYHuF7SHbQ5VMBqBrhYHbXirppYh4qtO6iFgTEfMjYn5l0wHoSpkj+EJJl9t+XtL9ki6xfV+tUwGohCOi/GL765J+FBFLC9aV3xTAEYkIF63hdXAgsQkdwUtvyhEcqF2ZI/jg0Rik3121YEnhmgee2HIUJgEmhsDHMTrqDQu3fuL3lz3+Fa1/7KM39V19cetpCUJHLyHwtvGO0hu0RXr8o9vL1Fr3s00/H3P9oUOHiB0945gP/IOwRx+NR1t28dJW5EAfOuYDL7L+sc1a1j4ib9CWD2NfduVHR/HTTzpv3H8ggCYReNs/Xv6bTj/pvDHvH8sGbdGyKzvvedWCJZymo1G8TNZ21YIlY15X/+TKW8Y8RV+mJVq3+pXCfb/7089K4noc1SvzMhmBjzLWE223vv3xMG+d0lqzbvUrH8bbCWGjLgR+hEaHfnjgo30Q+3iIG3Ui8Ap0epMLAaNJBA4kxg+bAMc4AgcSI3AgMQIHEiNwIDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCAxAgcSI3AgMQIHEiNwILFSgds+wfZG28/YHrZ9Yd2DAehe2U8XvUvSwxHxHduTJE2tcSYAFSn8ZBPb0yX9VdJpUfJjUPhkE6B+VX2yyWmSDkq61/Z222ttT+t6OgC1KxP4oKTzJd0dEfMkvSVp1eGLbK+wPWR7qOIZARyhMqfoJ0t6IiLmtG9/TdKqiLisw9dwig7UrJJT9Ih4UdI+22e271okaVeXswE4Ckp9fLDtL0taK2mSpD2Sro2I1zqs5wgO1IzPBwcS4/PBgWMcgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJDYYB2bzpg2XYu+eGEdWwOQ9Icdfy61rpbAZ581XXc+vriOrQFI+tYFO0utqyXwf735in7x2G87rjn7zC8U7jP8bPFfotf26cWZ2KdYr81UtM/r7/63cA+ppsDH028PYtl9enEm9inWazNNZJ933nm7cK10FAPv5wfzWNynF2din4mrPfBeexAI4NjdpxdnqjNuqebAe+1BYJ9ivTYT+3SnlsAnT55S+BfoxwezzD69OBP7FOu1maqIW5IcEZVsNNqJp346Fn9/VuX7Amj5/a9G9Or+/7loXS1H8Jknnqzblt9Ux9YAJF3+u9tKrSv1VlXbN9reaftp2+ttT+5qOgBHRWHgtmdKul7S/Ig4V9KApOV1Dwage2V/2GRQ0hTbg5KmStpf30gAqlIYeES8IOl2SXslHZD0ekRsOXyd7RW2h2wPvfraf6qfFMCElTlFnyHpCklzJZ0qaZrtaw5fFxFrImJ+RMw/ccbx1U8KYMLKnKIvlvRcRByMiHclbZJ0Ub1jAahCmcD3Slpge6ptS1okabjesQBUocw1+FZJGyVtk7Sj/TVrap4LQAVKvdElIlZLWl3zLAAqxv/JBiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4k5oioflP7oKR/llh6kqSXKx+gPv00bz/NKvXXvL0w6+cj4nNFi2oJvCzbQxExv7EBJqif5u2nWaX+mrefZuUUHUiMwIHEmg58TcN//kT107z9NKvUX/P2zayNXoMDqFfTR3AANWoscNuX2n7W9m7bq5qao4jt2bYftT1se6ftlU3PVIbtAdvbbW9uepZObJ9ge6PtZ9qP8YVNz9SJ7Rvb3wdP215ve3LTM3XSSOC2ByT9UtI3JZ0j6Wrb5zQxSwnvSbopIs6WtEDSD3p41tFWShpueogS7pL0cEScJelL6uGZbc+UdL2k+RFxrqQBScubnaqzpo7gF0jaHRF7IuKQpPslXdHQLB1FxIGI2Nb+9ZtqfQPObHaqzmzPknSZpLVNz9KJ7emSLpb0a0mKiEMR8e9mpyo0KGmK7UFJUyXtb3iejpoKfKakfaNuj6jHo5Ek23MkzZO0tdlJCt0p6WZJ7zc9SIHTJB2UdG/7cmKt7WlNDzWeiHhB0u2S9ko6IOn1iNjS7FSdNRW4x7ivp5/Ot328pAck3RARbzQ9z3hsL5X0UkQ81fQsJQxKOl/S3RExT9Jbknr5+ZgZap1pzpV0qqRptq9pdqrOmgp8RNLsUbdnqYdPdWwfp1bc6yJiU9PzFFgo6XLbz6t16XOJ7fuaHWlcI5JGIuKDM6KNagXfqxZLei4iDkbEu5I2Sbqo4Zk6airwJyWdYXuu7UlqPVHxYEOzdGTbal0jDkfEHU3PUyQifhwRsyJijlqP6x8joiePMhHxoqR9ts9s37VI0q4GRyqyV9IC21Pb3xeL1MNPCkqtU6SjLiLes32dpEfUeibynojY2cQsJSyU9D1JO2z/pX3fLRHxUIMzZfJDSeva/9DvkXRtw/OMKyK22t4oaZtar65sV4+/q413sgGJ8U42IDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxL7PytRi5zibsScAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# 新建一个游戏\n",
    "game = GameState()\n",
    "\n",
    "fig = plt.figure()\n",
    "axe = fig.add_subplot(111)\n",
    "dat = np.zeros((10, 10))\n",
    "img = axe.imshow(dat)\n",
    "\n",
    "# 进行100步循环，并将每一帧的画面打印出来\n",
    "for i in range(100):\n",
    "    clear_output(wait = True)\n",
    "    image_data, reward, terminal = game.frame_step([0,1])\n",
    "    \n",
    "    image = np.transpose(image_data, (1, 0, 2))\n",
    "    img.set_data(image)\n",
    "    img.autoscale()\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、训练神经网络玩游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  导入必需的包\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2 #需要安装OpenCV的包\n",
    "import sys\n",
    "sys.path.append(\"game/\")\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# 定义一系列常数，其中，epsilon为每周期随机输出一个动作的概率\n",
    "GAME = 'bird' # 游戏名称\n",
    "ACTIONS = 2 # 有效输出动作的个数\n",
    "GAMMA = 0.99 # 强化学习中未来的衰减率\n",
    "OBSERVE = 10000. # 训练之前的时间步，需要先观察10000帧\n",
    "EXPLORE = 3000000. # 退火所需的时间步，所谓的退火就是指随机选择率epsilon逐渐变小\n",
    "FINAL_EPSILON = 0.0001 # epsilon的最终值\n",
    "INITIAL_EPSILON = 0.1 # epsilon的初始值\n",
    "REPLAY_MEMORY = 50000 # 最多记忆多少帧训练数据\n",
    "BATCH = 32 # 每一个批次的数据记录条数\n",
    "FRAME_PER_ACTION = 1 # 每间隔多少时间完成一次有效动作的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建一个多层CNN网络，该网络接收的输入为4帧画面，输出为每个可能动作对应的Q函数值\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 第一层卷积，从4通道到32通道，窗口大小8，跳跃间隔4，填空白2\n",
    "        self.conv1 = nn.Conv2d(4, 32, 8, 4, padding = 2)\n",
    "        # Pooling层，窗口2*2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # 第二层卷积，从32通道到64通道，窗口大小4，跳跃间隔2，填空白1\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, 2, padding = 1)\n",
    "        # 第二个Pooling层，窗口2＊2，空白1\n",
    "        #self.pool2 = nn.MaxPool2d(2, 2, padding = 1)\n",
    "        # 第三层卷积层，输入输出通道都是64，填空白为1\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1, padding = 1)\n",
    "        \n",
    "        # 最后有两层全链接层\n",
    "        self.fc_sz = 1600\n",
    "        self.fc1 = nn.Linear(self.fc_sz, 256)\n",
    "        self.fc2 = nn.Linear(256, ACTIONS)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入为一个batch的数据，每一个为前后相连的4张图像，每个图像为80*80的大小\n",
    "        # x的尺寸为：batch_size, 4, 80, 80\n",
    "        x = self.conv1(x)\n",
    "        # x的尺寸为：batch_size, 32, 20, 20\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # x的尺寸为：batch_size, 32, 10, 10\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # x的尺寸为：batch_size, 64, 5, 5\n",
    "        #x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # x的尺寸为：batch_size, 64, 5, 5\n",
    "        #x = self.pool2(x)\n",
    "        # 将x设为1600维的向量, batch_size, 1600\n",
    "        x = x.view(-1, self.fc_sz)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        readout = self.fc2(x)\n",
    "        return readout, x\n",
    "    def init(self):\n",
    "        # 初始化所有的网络权重\n",
    "        self.conv1.weight.data =  torch.abs(0.01 * torch.randn(self.conv1.weight.size()))\n",
    "        self.conv2.weight.data =  torch.abs(0.01 * torch.randn(self.conv2.weight.size()))\n",
    "        self.conv3.weight.data =  torch.abs(0.01 * torch.randn(self.conv3.weight.size()))\n",
    "        self.fc1.weight.data = torch.abs(0.01 * torch.randn(self.fc1.weight.size()))\n",
    "        self.fc2.weight.data = torch.abs(0.01 * torch.randn(self.fc2.weight.size()))\n",
    "        self.conv1.bias.data = torch.ones(self.conv1.bias.size()) * 0.01\n",
    "        self.conv2.bias.data = torch.ones(self.conv2.bias.size()) * 0.01\n",
    "        self.conv3.bias.data = torch.ones(self.conv3.bias.size()) * 0.01\n",
    "        self.fc1.bias.data = torch.ones(self.fc1.bias.size()) * 0.01\n",
    "        self.fc2.bias.data = torch.ones(self.fc2.bias.size()) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始在内存／GPU上定义一个网络\n",
    "use_cuda = torch.cuda.is_available() #检测本台机器中是否有GPU\n",
    "\n",
    "# 创建一个神经网络\n",
    "net = Net()\n",
    "# 初始化网络权重。之所以自定义初始化过程是为了增加神经网络权重的多样性\n",
    "net.init()\n",
    "# 如果有GPU，就把神经网络全部搬到GPU内存中做运算\n",
    "net = net.cuda() if use_cuda else net\n",
    "\n",
    "# 定义损失函数为MSE\n",
    "criterion = nn.MSELoss().cuda() if use_cuda else nn.MSELoss()\n",
    "# 定义优化器，并设置初始学习率维10^-6\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-6 )\n",
    "\n",
    "# 开启一个游戏进程，开始与游戏引擎通话\n",
    "game_state = GameState()\n",
    "\n",
    "# 学习样本的存储区域deque是一个类似于list的存储容器\n",
    "D = deque()\n",
    "\n",
    "# 状态打印log记录位置\n",
    "#a_file = open(\"logs_\" + GAME + \"/readout.txt\", 'w')\n",
    "#h_file = open(\"logs_\" + GAME + \"/hidden.txt\", 'w')\n",
    "\n",
    "# 将游戏设置为初始状态，并获得一个80*80的游戏湖面\n",
    "do_nothing = np.zeros(ACTIONS)\n",
    "do_nothing[0] = 1\n",
    "x_t, r_0, terminal = game_state.frame_step(do_nothing)\n",
    "x_t = cv2.cvtColor(cv2.resize(x_t, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "ret, x_t = cv2.threshold(x_t,1,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# 将初始的游戏画面叠加成4张作为神经网络的初始输入状态s_t\n",
    "s_t = np.stack((x_t, x_t, x_t, x_t), axis=0)\n",
    "\n",
    "# 设置初始的epsilon（采取随机行动的概率），并准备训练\n",
    "epsilon = INITIAL_EPSILON\n",
    "t = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 边做边学的核心算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该算法分为三个阶段：\n",
    "\n",
    "1、按照Epsilon贪婪算法采取一次行动；\n",
    "2、将选择好的行动输入给游戏引擎，得到下一帧的状态，并生成本帧的训练数据\n",
    "3、开始训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记录每轮平均得分的容器\n",
    "scores = []\n",
    "all_turn_scores = []\n",
    "while \"flappy bird\" != \"angry bird\":\n",
    "    # 开始游戏循环\n",
    "    ######################################################\n",
    "    ##########首先，按照贪婪策略选择一个行动 ##################\n",
    "    s = torch.from_numpy(s_t).type(torch.FloatTensor).requires_grad_(True)\n",
    "    s = s.cuda() if use_cuda else s\n",
    "    s = s.view(-1, s.size()[0], s.size()[1], s.size()[2])\n",
    "    # 获取当前时刻的游戏画面，输入到神经网络中\n",
    "    readout, h_fc1 = net(s)\n",
    "    # 神经网络产生的输出为readout：选择每一个行动的预期Q值\n",
    "    readout = readout.cpu() if use_cuda else readout\n",
    "    # readout为一个二维向量，分别对应每一个动作的预期Q值\n",
    "    readout_t = readout.data.numpy()[0]\n",
    "\n",
    "    # 按照epsilon贪婪策略产生小鸟的行动，即以epsilon的概率随机输出行动或者以\n",
    "    # 1-epsilon的概率按照预期输出最大的Q值给出行动\n",
    "    a_t = np.zeros([ACTIONS])\n",
    "    action_index = 0\n",
    "    if t % FRAME_PER_ACTION == 0:\n",
    "        # 如果当前帧可以行动，则\n",
    "        if random.random() <= epsilon:\n",
    "            # 产生随机行动\n",
    "            #print(\"----------Random Action----------\")\n",
    "            action_index = random.randrange(ACTIONS)\n",
    "        else:\n",
    "            # 选择神经网络判断的预期Q最大的行动\n",
    "            action_index = np.argmax(readout_t)\n",
    "        a_t[action_index] = 1\n",
    "    else:\n",
    "        a_t[0] = 1 # do nothing\n",
    "\n",
    "    # 模拟退火：让epsilon开始降低\n",
    "    if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "        epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "\n",
    "    ######################################################################### \n",
    "    ##########其次，将选择好的行动输入给游戏引擎，并得到下一帧的状态 ################### \n",
    "    x_t1_colored, r_t, terminal = game_state.frame_step(a_t)\n",
    "    # 返回的x_t1_colored为游戏画面，r_t为本轮的得分，terminal为游戏在本轮是否已经结束\n",
    "    \n",
    "    # 记录一下每一步的成绩\n",
    "    scores.append(r_t)\n",
    "    if terminal:\n",
    "        # 当游戏结束的时候，计算一下本轮的总成绩，并将总成绩存储到all_turn_scores中\n",
    "        all_turn_scores.append(sum(scores))\n",
    "        scores = []\n",
    "    \n",
    "    # 对游戏的原始画面做相应的处理，从而变成一张80*80的，朴素的（无背景画面）的图\n",
    "    x_t1 = cv2.cvtColor(cv2.resize(x_t1_colored, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, x_t1 = cv2.threshold(x_t1, 1, 255, cv2.THRESH_BINARY)\n",
    "    x_t1 = np.reshape(x_t1, (1, 80, 80))\n",
    "    # 将当前帧的画面和前三帧的画面合并起来作为Agent获得的环境反馈结果\n",
    "    s_t1 = np.append(x_t1, s_t[:3, :, :], axis=0)\n",
    "    # 生成一个训练数据，分别将本帧的输入画面s_t,本帧的行动a_t，得到的环境回报r_t以及环境被转换的新状态s_t1存到D中\n",
    "    D.append((s_t, a_t, r_t, s_t1, terminal))\n",
    "    if len(D) > REPLAY_MEMORY:\n",
    "        # 如果D中的元素已满，则扔掉最老的一条训练数据\n",
    "        D.popleft()\n",
    "\n",
    "    ######################################################################### \n",
    "    ##########最后，当运行周期超过一定次数后开始训练神经网络 ################### \n",
    "    if t > OBSERVE:\n",
    "        # 从D中随机采样出一个batch的训练数据\n",
    "        minibatch = random.sample(D, BATCH)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 将这个batch中的s变量都分别存放到列表中\n",
    "        s_j_batch = [d[0] for d in minibatch]\n",
    "        a_batch = [d[1] for d in minibatch]\n",
    "        r_batch = [d[2] for d in minibatch]\n",
    "        s_j1_batch = [d[3] for d in minibatch]\n",
    "\n",
    "        # 接下来，要根据s_j1_batch，神经网络给出预估的未来Q值\n",
    "        \n",
    "        s = torch.tensor(np.array(s_j1_batch, dtype=float), dtype = torch.float, requires_grad = True)\n",
    "        s = s.cuda() if use_cuda else s\n",
    "        readout, h_fc1 = net(s)\n",
    "        readout = readout.cpu() if use_cuda else readout\n",
    "        readout_j1_batch = readout.data.numpy()\n",
    "        # readout_j1_batch存储了一个minibatch中的所有未来一步的Q预估值\n",
    "        # 根据Q的预估值，当前的反馈r，以及游戏是否结束，更新待训练的目标函数值\n",
    "        y_batch = []\n",
    "        for i in range(0, len(minibatch)):\n",
    "            terminal = minibatch[i][4]\n",
    "            # 当游戏结束的时候，则用环境的反馈作为目标，否则用下一状态的Q值＋本期的环境反馈\n",
    "            if terminal:\n",
    "                y_batch.append(r_batch[i])\n",
    "            else:\n",
    "                y_batch.append(r_batch[i] + GAMMA * np.max(readout_j1_batch[i]))\n",
    "\n",
    "        # 开始梯度更新\n",
    "        y = torch.tensor(y_batch, dtype = torch.float, requires_grad = True)\n",
    "        a = torch.tensor(a_batch, dtype = torch.float, requires_grad = True)\n",
    "        s = torch.tensor(np.array(s_j_batch, dtype=float), dtype = torch.float, requires_grad = True)\n",
    "        if use_cuda:\n",
    "            y = y.cuda()\n",
    "            a = a.cuda()\n",
    "            s = s.cuda()\n",
    "        # 计算s_j_batch的Q值\n",
    "        readout, h_fc1 = net(s)\n",
    "        readout_action = readout.mul(a).sum(1)\n",
    "        # 根据s_j_batch下所选择的预估Q和目标y的Q值的差来作为损失函数训练网络\n",
    "        loss = criterion(readout_action, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if t % 1000 == 0:\n",
    "            print('损失函数：', loss)\n",
    "       \n",
    "\n",
    "    # 将状态更新一次，时间步＋1\n",
    "    s_t = s_t1\n",
    "    t += 1\n",
    "\n",
    "    # 每隔 10000 次循环，存储一下网络\n",
    "    if t % 10000 == 0:\n",
    "        torch.save(net, 'saving_nets/' + GAME + '-dqn' + str(t) + '.txt')\n",
    "    \n",
    "    # 状态信息的转化，基本分为Observe，explore和train三个阶段\n",
    "    # Observe没有训练，explore开始训练，并且开始模拟退火，train模拟退火结束\n",
    "    state = \"\"\n",
    "    if t <= OBSERVE:\n",
    "        state = \"observe\"\n",
    "    elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "        state = \"explore\"\n",
    "    else:\n",
    "        state = \"train\"\n",
    "        \n",
    "    # 打印当前运行的一些基本数据，分别输出到屏幕以及log文件中\n",
    "    if t % 1000 == 0:\n",
    "        sss = \"时间步 {}/ 状态 {}/ Epsilon {:.2f}/ 行动 {}/ 奖励 {}/ Q_MAX {:e}/ 轮得分 {:.2f}\".format(\n",
    "            t, state, epsilon, action_index, r_t, np.max(readout_t), np.mean(all_turn_scores[-1000:]))\n",
    "        print(sss)\n",
    "        f = open('log_file.txt', 'a')\n",
    "        f.write(sss + '\\n')\n",
    "        f.close()\n",
    "    # write info to files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open('final_log_file.txt', 'r')\n",
    "line = f.read().strip().split('\\n')\n",
    "values = []\n",
    "for ln in line:\n",
    "    segs = ln.split('/')\n",
    "    values.append(float(segs[-1].split(' ')[-1]))\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(values))*1000, values)\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Average Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = torch.load('saving_nets/' + GAME + '-dqn' + str(2876000) + '.txt')\n",
    "net = torch.load('final_model.mdl')\n",
    "FINAL_EPSILON = 0.0001 # epsilon的最终值\n",
    "BATCH = 32 # 每一个批次的数据记录条数\n",
    "FRAME_PER_ACTION = 1 # 每间隔多少时间完成一次有效动作的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 开始在内存／GPU上定义一个网络\n",
    "use_cuda = torch.cuda.is_available() #检测本台机器中是否有GPU\n",
    "\n",
    "# 如果有GPU，就把神经网络全部搬到GPU内存中做运算\n",
    "net = net.cuda() if use_cuda else net\n",
    "\n",
    "# 开启一个游戏进程，开始与游戏引擎通话\n",
    "game_state = GameState()\n",
    "\n",
    "# 状态打印log记录位置\n",
    "#a_file = open(\"logs_\" + GAME + \"/readout.txt\", 'w')\n",
    "#h_file = open(\"logs_\" + GAME + \"/hidden.txt\", 'w')\n",
    "\n",
    "# 将游戏设置为初始状态，并获得一个80*80的游戏湖面\n",
    "do_nothing = np.zeros(ACTIONS)\n",
    "do_nothing[0] = 1\n",
    "x_t, r_0, terminal = game_state.frame_step(do_nothing)\n",
    "x_t = cv2.cvtColor(cv2.resize(x_t, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "ret, x_t = cv2.threshold(x_t,1,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# 将初始的游戏画面叠加成4张作为神经网络的初始输入状态s_t\n",
    "s_t = np.stack((x_t, x_t, x_t, x_t), axis=0)\n",
    "\n",
    "# 设置初始的epsilon（采取随机行动的概率），并准备训练\n",
    "epsilon = FINAL_EPSILON\n",
    "t = 0# 记录每轮平均得分的容器\n",
    "scores = []\n",
    "all_turn_scores = []\n",
    "\n",
    "fig = plt.figure()\n",
    "axe = fig.add_subplot(111)\n",
    "dat = np.zeros((10, 10))\n",
    "img = axe.imshow(dat)\n",
    "while \"flappy bird\" != \"angry bird\":\n",
    "    # 开始游戏循环\n",
    "    ######################################################\n",
    "    ##########首先，按照贪婪策略选择一个行动 ##################\n",
    "    s = torch.from_numpy(s_t).type(torch.FloatTensor).requires_grad_(False)\n",
    "    s = s.cuda() if use_cuda else s\n",
    "    s = s.view(-1, s.size()[0], s.size()[1], s.size()[2])\n",
    "    # 获取当前时刻的游戏画面，输入到神经网络中\n",
    "    readout, h_fc1 = net(s)\n",
    "    # 神经网络产生的输出为readout：选择每一个行动的预期Q值\n",
    "    readout = readout.cpu() if use_cuda else readout\n",
    "    # readout为一个二维向量，分别对应每一个动作的预期Q值\n",
    "    readout_t = readout.data.numpy()[0]\n",
    "\n",
    "    # 按照epsilon贪婪策略产生小鸟的行动，即以epsilon的概率随机输出行动或者以\n",
    "    # 1-epsilon的概率按照预期输出最大的Q值给出行动\n",
    "    a_t = np.zeros([ACTIONS])\n",
    "    action_index = 0\n",
    "    if t % FRAME_PER_ACTION == 0:\n",
    "        # 如果当前帧可以行动，则\n",
    "        if random.random() <= epsilon:\n",
    "            # 产生随机行动\n",
    "            #print(\"----------Random Action----------\")\n",
    "            action_index = random.randrange(ACTIONS)\n",
    "        else:\n",
    "            # 选择神经网络判断的预期Q最大的行动\n",
    "            action_index = np.argmax(readout_t)\n",
    "        a_t[action_index] = 1\n",
    "    else:\n",
    "        a_t[0] = 1 # do nothing\n",
    "    ######################################################################### \n",
    "    ##########其次，将选择好的行动输入给游戏引擎，并得到下一帧的状态 ################### \n",
    "    x_t1_colored, r_t, terminal = game_state.frame_step(a_t)\n",
    "    # 返回的x_t1_colored为游戏画面，r_t为本轮的得分，terminal为游戏在本轮是否已经结束\n",
    "    \n",
    "    # 记录一下每一步的成绩\n",
    "    scores.append(r_t)\n",
    "    if terminal:\n",
    "        # 当游戏结束的时候，计算一下本轮的总成绩，并将总成绩存储到all_turn_scores中\n",
    "        all_turn_scores.append(sum(scores))\n",
    "        scores = []\n",
    "    \n",
    "    # 对游戏的原始画面做相应的处理，从而变成一张80*80的，朴素的（无背景画面）的图\n",
    "    x_t1 = cv2.cvtColor(cv2.resize(x_t1_colored, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, x_t1 = cv2.threshold(x_t1, 1, 255, cv2.THRESH_BINARY)\n",
    "    x_t1 = np.reshape(x_t1, (1, 80, 80))\n",
    "    # 将当前帧的画面和前三帧的画面合并起来作为Agent获得的环境反馈结果\n",
    "    s_t1 = np.append(x_t1, s_t[:3, :, :], axis=0)\n",
    "    s_t = s_t1\n",
    "    t += 1\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    image = np.transpose(x_t1_colored, (1, 0, 2))\n",
    "    img.set_data(image)\n",
    "    img.autoscale()\n",
    "    display(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
